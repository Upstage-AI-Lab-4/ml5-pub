{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "from spotipy.exceptions import SpotifyException\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/1 processed.\n",
      "Chunk 1/1 processed.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 239\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# 업데이트한 차트 기반으로 데이터베이스 업데이트\u001b[39;00m\n\u001b[1;32m    238\u001b[0m spotify_api \u001b[38;5;241m=\u001b[39m get_info(sp)\n\u001b[0;32m--> 239\u001b[0m \u001b[43mspotify_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 222\u001b[0m, in \u001b[0;36mget_info.fetch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(df1_selected, df2_selected, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# 순서 맞추기\u001b[39;00m\n\u001b[0;32m--> 222\u001b[0m df_combined \u001b[38;5;241m=\u001b[39m \u001b[43mdf_combined\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;66;03m# 원본 뒤에 붙이고 저장하기\u001b[39;00m\n\u001b[1;32m    225\u001b[0m df_merged \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df_combined], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/MLops/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/MLops/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/MLops/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not in index\""
     ]
    }
   ],
   "source": [
    "import time\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "from spotipy.exceptions import SpotifyException\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "# from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "# 스포티파이 api키 입력\n",
    "client_id = '9138c9fe66ce41dfa7ab1b83ecf6f650'\n",
    "client_secret = '9521407805044cb7a9573a36519197c1'\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "\n",
    "# 스포티파이 위클리 차트 csv파일 저장\n",
    "class Spotify_weekly_chart:\n",
    "    def __init__(self, countries, download_directory=\"/Users/kwonsejin/Desktop/MLops/data/spotify_charts/\"): #다운로드 경로는 도커 만들고나서 절대경로로 설정해야함\n",
    "        self.countries = countries\n",
    "        self.download_directory = download_directory\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\": self.download_directory}\n",
    "        self.options.add_experimental_option(\"prefs\", prefs)\n",
    "        self.driver = None\n",
    "\n",
    "    def download_charts(self, username, password):\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.options)\n",
    "        self.driver.get(\"https://charts.spotify.com/charts/view/regional-global-weekly/latest\")\n",
    "\n",
    "        # 쿠키 배너 처리\n",
    "        try:\n",
    "            accept_cookies = WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, 'onetrust-accept-btn-handler'))\n",
    "            )\n",
    "            accept_cookies.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 로그인 하기\n",
    "        login_button = WebDriverWait(self.driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.LINK_TEXT, 'Log in'))\n",
    "        )\n",
    "        login_button.click()\n",
    "\n",
    "        id_input = WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'login-username'))\n",
    "        )\n",
    "        id_input.send_keys(username)\n",
    "\n",
    "        password_input = self.driver.find_element(By.ID, 'login-password')\n",
    "        password_input.send_keys(password)\n",
    "\n",
    "        login_button = self.driver.find_element(By.ID, 'login-button')\n",
    "        login_button.click()\n",
    "\n",
    "        #로그인 후 로딩대기\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.url_contains('charts.spotify.com/charts')\n",
    "        )\n",
    "\n",
    "        before_files = set(os.listdir(self.download_directory)) #변경 전 파일이름들 확인\n",
    "\n",
    "        #나라별 200차트 다운로드\n",
    "        for country in self.countries:\n",
    "            self.driver.get(f\"https://charts.spotify.com/charts/view/regional-{country}-weekly/latest\")\n",
    "            time.sleep(2) # 다운로드 버튼 로딩 대기\n",
    "            \n",
    "            csv_download_button = WebDriverWait(self.driver, 60).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@aria-labelledby='csv_download']\"))\n",
    "            )\n",
    "            csv_download_button.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # 크롬 셀레늄 끝내기\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "        #이전파일과 비교해 업데이트된 파일 찾기\n",
    "        after_files = set(os.listdir(self.download_directory))\n",
    "        new_files = after_files - before_files\n",
    "        new_files = list(new_files)\n",
    "\n",
    "        # 업데이트된 파일들 합치고 저장하기\n",
    "        new_chart = []\n",
    "        for file in new_files:\n",
    "            df = pd.read_csv(f'{self.download_directory + file}')\n",
    "            new_chart.append(df)\n",
    "\n",
    "        combined_chart = pd.concat(new_chart, ignore_index=True)\n",
    "        combined_chart['id'] = combined_chart['uri'].str.split(':').str[2]\n",
    "        file_name = new_files[0].split('-')[3:]\n",
    "        file_name = ''.join(file_name[:-1]) + file_name[-1]\n",
    "        combined_chart.to_csv(f'{self.download_directory}combined_{file_name}', index=False)\n",
    "\n",
    "        #중복 삭제후 추가된곡만 저장\n",
    "        exist_songs = pd.read_csv('../data/spotify_songs_new.csv') #도커 올리고 나서 경로수정 해야함\n",
    "        exist_id = set(exist_songs['track_id'])\n",
    "        new_songs = combined_chart[~combined_chart['id'].isin(exist_id)]\n",
    "        new_songs.to_csv('/Users/kwonsejin/Desktop/MLops/data/new_songs.csv', index=False) #도커 올리고 나서 경로수정 해야함\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Rate limit에 맞추어 요청 수 제한\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_calls, period):\n",
    "        self.max_calls = max_calls\n",
    "        self.period = period\n",
    "        self.calls = []\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def acquire(self):\n",
    "        with self.lock:\n",
    "            current_time = time.time()\n",
    "            # 기간 내의 호출만 남김\n",
    "            self.calls = [call for call in self.calls if current_time - call < self.period]\n",
    "            if len(self.calls) >= self.max_calls:\n",
    "                # 기간이 끝날 때까지 대기\n",
    "                sleep_time = self.period - (current_time - self.calls[0])\n",
    "                print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "                time.sleep(sleep_time)\n",
    "                # 대기 후 호출 리스트 갱신\n",
    "                self.calls = [call for call in self.calls if time.time() - call < self.period]\n",
    "            # 호출 기록 추가\n",
    "            self.calls.append(time.time())\n",
    "\n",
    "\n",
    "\n",
    "# 새로운 위클리차트 기반으로 데이터베이스 업데이트\n",
    "class get_info:\n",
    "    def __init__(self, sp):\n",
    "        self.sp = sp\n",
    "        self.ids= pd.read_csv('../data/new_songs.csv')['id'].tolist() #도커 올리고 나서 경로수정 해야함\n",
    "        self.rate_limiter = RateLimiter(max_calls=5, period=30)\n",
    "\n",
    "    def chunk_ids(self, chunk_size):\n",
    "        \"\"\"IDs를 chunk_size 크기로 분할하는 제너레이터 함수\"\"\"\n",
    "        for i in range(0, len(self.ids), chunk_size):\n",
    "            yield self.ids[i:i + chunk_size]\n",
    "    \n",
    "    def get_audio_features(self):\n",
    "        audio_features = []\n",
    "        id_chunks = list(self.chunk_ids(100))\n",
    "        total_chunks = len(id_chunks)\n",
    "        for idx, chunk in enumerate(id_chunks):\n",
    "            self.rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "            try:\n",
    "                features = self.sp.audio_features(chunk)\n",
    "                if features is not None:\n",
    "                    audio_features.extend(features)\n",
    "                else:\n",
    "                    print(f\"Chunk {idx+1}/{total_chunks}: Received None for features.\")\n",
    "                print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching audio features for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "        return audio_features\n",
    "    \n",
    "    def get_track_info(self):\n",
    "        track_info = []\n",
    "        id_chunks = list(self.chunk_ids(50))\n",
    "        total_chunks = len(id_chunks)\n",
    "        for idx, chunk in enumerate(id_chunks):\n",
    "            self.rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "            try:\n",
    "                response = self.sp.tracks(chunk)\n",
    "                if response is not None:\n",
    "                    track_info.extend(response['tracks'])\n",
    "                else:\n",
    "                    print(f\"Chunk {idx+1}/{total_chunks}: Received None for features.\")\n",
    "                print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching track_info for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "        return track_info\n",
    "    \n",
    "    def fetch(self):\n",
    "        df = pd.read_csv('../data/spotify_songs_new.csv')\n",
    "        audio_features = self.get_audio_features()\n",
    "        features = pd.DataFrame(audio_features)\n",
    "\n",
    "        track_infos = self.get_track_info()\n",
    "        infos = pd.DataFrame(track_infos)\n",
    "\n",
    "        # infos['artists'] = infos['artists'].apply(ast.literal_eval)\n",
    "        # infos['album'] = infos['album'].apply(ast.literal_eval)    #필요없는듯?\n",
    "\n",
    "        infos['track_artist'] = infos['artists'].apply(lambda x: ', '.join([artist['name'] for artist in x]))\n",
    "        infos['track_album_id'] = infos['album'].apply(lambda x: x['id'])\n",
    "        infos['track_album_name'] = infos['album'].apply(lambda x: x['name'])\n",
    "        infos['track_album_release_date'] = infos['album'].apply(lambda x: x['release_date'])\n",
    "\n",
    "        features.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "        infos.rename(columns={'id': 'track_id', 'name': 'track_name', 'popularity': 'track_popularity'}, inplace=True)\n",
    "\n",
    "        # 필요한거 골라서 합치기\n",
    "        df1_selected = features[['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                            'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                            'valence', 'tempo', 'duration_ms']]\n",
    "\n",
    "        df2_selected = infos[['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
    "                            'track_album_id', 'track_album_name', 'track_album_release_date']]\n",
    "\n",
    "        df_combined = pd.merge(df1_selected, df2_selected, on='track_id', how='inner')\n",
    "\n",
    "        # 순서 맞추기\n",
    "        if 'Unnamed: 0' in df.columns:\n",
    "            df = df.drop(columns=['Unnamed: 0'])\n",
    "        df_combined = df_combined[df.columns]\n",
    "\n",
    "        # 원본 뒤에 붙이고 저장하기\n",
    "        df_merged = pd.concat([df, df_combined], ignore_index=True)\n",
    "        df_merged.drop_duplicates(subset='track_id', inplace=True)\n",
    "        df_merged.to_csv('../data/spotify_songs_new.csv', index=False)\n",
    "\n",
    "\n",
    "# 위 클래스들 사용법\n",
    "\n",
    "# 위클리차트 업데이트\n",
    "countries = ['kr', 'us', 'global']\n",
    "downloader = Spotify_weekly_chart(countries)\n",
    "downloader.download_charts('sejin_kwon@naver.com', 'qykfab-5reZqu-pafhug') #아이디, 패스워드 입력\n",
    "\n",
    "# 업데이트한 차트 기반으로 데이터베이스 업데이트\n",
    "spotify_api = get_info(sp)\n",
    "spotify_api.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스포티파이 api키 입력\n",
    "client_id = '9138c9fe66ce41dfa7ab1b83ecf6f650'\n",
    "client_secret = '9521407805044cb7a9573a36519197c1'\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = webdriver.ChromeOptions()\n",
    "# prefs = {\"download.default_directory\": \"./data/spotify_files/\"}\n",
    "# options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "# # Countries and specific dates\n",
    "# countries = ['kr', 'us', 'global']\n",
    "\n",
    "# with webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options) as driver:\n",
    "#     driver.get(\"https://charts.spotify.com/charts/view/regional-global-weekly/latest\")\n",
    "    \n",
    "#     # Handle cookie banner if present\n",
    "#     try:\n",
    "#         accept_cookies = WebDriverWait(driver, 10).until(\n",
    "#             EC.element_to_be_clickable((By.ID, 'onetrust-accept-btn-handler'))\n",
    "#         )\n",
    "#         accept_cookies.click()\n",
    "#     except:\n",
    "#         pass  # If not present, continue\n",
    "\n",
    "#     # Wait for the login button and click it\n",
    "#     login_button = WebDriverWait(driver, 10).until(\n",
    "#         EC.element_to_be_clickable((By.LINK_TEXT, 'Log in'))\n",
    "#     )\n",
    "#     login_button.click()\n",
    "\n",
    "#     # Wait for the login form fields\n",
    "#     id_input = WebDriverWait(driver, 10).until(\n",
    "#         EC.presence_of_element_located((By.ID, 'login-username'))\n",
    "#     )\n",
    "#     id_input.send_keys('sejin_kwon@naver.com')\n",
    "\n",
    "#     password_input = driver.find_element(By.ID, 'login-password')\n",
    "#     password_input.send_keys('qykfab-5reZqu-pafhug')\n",
    "\n",
    "#     login_button = driver.find_element(By.ID, 'login-button')\n",
    "#     login_button.click()\n",
    "\n",
    "#     # Wait for login to complete\n",
    "#     WebDriverWait(driver, 10).until(\n",
    "#         EC.url_contains('charts.spotify.com/charts')\n",
    "#     )\n",
    "\n",
    "#     # CSV File Download for specific dates\n",
    "#     for country in countries:\n",
    "#         driver.get(f\"https://charts.spotify.com/charts/view/regional-{country}-weekly/latest\")\n",
    "#         time.sleep(2)\n",
    "#         # Wait for the download button to be clickable\n",
    "#         csv_download_button = WebDriverWait(driver, 60).until(\n",
    "#             EC.element_to_be_clickable((By.XPATH, \"//button[@aria-labelledby='csv_download']\"))\n",
    "#         )\n",
    "#         csv_download_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Spotify_weekly_chart:\n",
    "    def __init__(self, countries, download_directory=\"../data/spotify_charts/\"): #다운로드 경로는 도커 만들고나서 절대경로로 설정해야함\n",
    "        self.countries = countries\n",
    "        self.download_directory = download_directory\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        prefs = {\"download.default_directory\": self.download_directory}\n",
    "        self.options.add_experimental_option(\"prefs\", prefs)\n",
    "        self.driver = None\n",
    "\n",
    "    def download_charts(self, username, password):\n",
    "        self.driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=self.options)\n",
    "        self.driver.get(\"https://charts.spotify.com/charts/view/regional-global-weekly/latest\")\n",
    "\n",
    "        # 쿠키 배너 처리\n",
    "        try:\n",
    "            accept_cookies = WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, 'onetrust-accept-btn-handler'))\n",
    "            )\n",
    "            accept_cookies.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 로그인 하기\n",
    "        login_button = WebDriverWait(self.driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.LINK_TEXT, 'Log in'))\n",
    "        )\n",
    "        login_button.click()\n",
    "\n",
    "        id_input = WebDriverWait(self.driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, 'login-username'))\n",
    "        )\n",
    "        id_input.send_keys(username)\n",
    "\n",
    "        password_input = self.driver.find_element(By.ID, 'login-password')\n",
    "        password_input.send_keys(password)\n",
    "\n",
    "        login_button = self.driver.find_element(By.ID, 'login-button')\n",
    "        login_button.click()\n",
    "\n",
    "        #로그인 후 로딩대기\n",
    "        WebDriverWait(self.driver, 10).until(\n",
    "            EC.url_contains('charts.spotify.com/charts')\n",
    "        )\n",
    "\n",
    "        before_files = set(os.listdir(self.download_directory)) #변경 전 파일이름들 확인\n",
    "\n",
    "        #나라별 200차트 다운로드\n",
    "        for country in self.countries:\n",
    "            self.driver.get(f\"https://charts.spotify.com/charts/view/regional-{country}-weekly/latest\")\n",
    "            time.sleep(2) # 다운로드 버튼 로딩 대기\n",
    "            \n",
    "            csv_download_button = WebDriverWait(self.driver, 60).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//button[@aria-labelledby='csv_download']\"))\n",
    "            )\n",
    "            csv_download_button.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # 크롬 셀레늄 끝내기\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "        #이전파일과 비교해 업데이트된 파일 찾기\n",
    "        after_files = set(os.listdir(self.download_directory))\n",
    "        new_files = after_files - before_files\n",
    "        new_files = list(new_files)\n",
    "\n",
    "        # 업데이트된 파일들 합치고 저장하기\n",
    "        new_chart = []\n",
    "        for file in new_files:\n",
    "            df = pd.read_csv(f'{self.download_directory + file}')\n",
    "            new_chart.append(df)\n",
    "\n",
    "        combined_chart = pd.concat(new_chart, ignore_index=True)\n",
    "        file_name = new_files[0].split('-')[3:]\n",
    "        combined_chart.to_csv(f'{self.download_directory}combined_{file_name}')\n",
    "\n",
    "        #중복 삭제후 추가된곡만 저장\n",
    "        exist_songs = pd.read_csv('../data/spotify_songs_new.csv') #도커 올리고 나서 경로수정 해야함\n",
    "        exist_id = set(exist_songs['id'])\n",
    "        new_songs = combined_chart[~combined_chart['id'].isin(exist_id)]\n",
    "        new_songs.to_csv('/Users/kwonsejin/Desktop/MLops/data/new_songs.csv', index=False) #도커 올리고 나서 경로수정 해야함\n",
    "\n",
    "\n",
    "## 위에서 합친 파일 id들이랑 원본 데이터 id들이랑 비교해서 중복 삭제하고 리스트 만들기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 클래스 사용법\n",
    "countries = ['kr', 'us', 'global']\n",
    "\n",
    "downloader = Spotify_weekly_chart(countries)\n",
    "\n",
    "downloader.download_charts('sejin_kwon@naver.com', 'qykfab-5reZqu-pafhug') #아이디, 패스워드 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 새로운 노래 id들 불러오기\n",
    "# df = pd.read_csv('../data/new_songs.csv')\n",
    "# ids = pd.read_csv('../data/new_songs.csv')['id'].tolist()\n",
    "\n",
    "# # 한번에 호출할 수 있는 100개에 맞추어 자르기\n",
    "# def chunk_ids(ids, chunk_size=100):\n",
    "#     for i in range(0, len(ids), chunk_size):\n",
    "#         yield ids[i:i + chunk_size]\n",
    "\n",
    "# id_chunks = list(chunk_ids(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate limit에 맞추어 요청 수 제한\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_calls, period):\n",
    "        self.max_calls = max_calls\n",
    "        self.period = period\n",
    "        self.calls = []\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def acquire(self):\n",
    "        with self.lock:\n",
    "            current_time = time.time()\n",
    "            # 기간 내의 호출만 남김\n",
    "            self.calls = [call for call in self.calls if current_time - call < self.period]\n",
    "            if len(self.calls) >= self.max_calls:\n",
    "                # 기간이 끝날 때까지 대기\n",
    "                sleep_time = self.period - (current_time - self.calls[0])\n",
    "                print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds.\")\n",
    "                time.sleep(sleep_time)\n",
    "                # 대기 후 호출 리스트 갱신\n",
    "                self.calls = [call for call in self.calls if time.time() - call < self.period]\n",
    "            # 호출 기록 추가\n",
    "            self.calls.append(time.time())\n",
    "\n",
    "\n",
    "\n",
    "rate_limiter = RateLimiter(max_calls=5, period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_info:\n",
    "    def __init__(self, sp):\n",
    "        self.sp = sp\n",
    "        self.ids= pd.read_csv('../data/new_songs.csv')['id'].tolist() #도커 올리고 나서 경로수정 해야함\n",
    "        self.rate_limiter = RateLimiter(max_calls=5, period=30)\n",
    "\n",
    "    def chunk_ids(self, chunk_size):\n",
    "        \"\"\"IDs를 chunk_size 크기로 분할하는 제너레이터 함수\"\"\"\n",
    "        for i in range(0, len(self.ids), chunk_size):\n",
    "            yield self.ids[i:i + chunk_size]\n",
    "    \n",
    "    def get_audio_features(self):\n",
    "        audio_features = []\n",
    "        id_chunks = list(self.chunk_ids(100))\n",
    "        total_chunks = len(id_chunks)\n",
    "        for idx, chunk in enumerate(id_chunks):\n",
    "            self.rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "            try:\n",
    "                features = self.sp.audio_features(chunk)\n",
    "                if features is not None:\n",
    "                    audio_features.extend(features)\n",
    "                else:\n",
    "                    print(f\"Chunk {idx+1}/{total_chunks}: Received None for features.\")\n",
    "                print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching audio features for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "        return audio_features\n",
    "    \n",
    "    def get_track_info(self):\n",
    "        track_info = []\n",
    "        id_chunks = list(self.chunk_ids(50))\n",
    "        total_chunks = len(id_chunks)\n",
    "        for idx, chunk in enumerate(id_chunks):\n",
    "            self.rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "            try:\n",
    "                response = self.sp.tracks(chunk)\n",
    "                if response is not None:\n",
    "                    track_info.extend(response['tracks'])\n",
    "                else:\n",
    "                    print(f\"Chunk {idx+1}/{total_chunks}: Received None for features.\")\n",
    "                print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching track_info for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "        return track_info\n",
    "    \n",
    "    def fetch(self):\n",
    "        df = pd.read_csv('../data/spotify_songs_new.csv')\n",
    "        audio_features = self.get_audio_features()\n",
    "        features = pd.DataFrame(audio_features)\n",
    "\n",
    "        track_infos = self.get_track_info()\n",
    "        infos = pd.DataFrame(track_infos)\n",
    "\n",
    "        # infos['artists'] = infos['artists'].apply(ast.literal_eval)\n",
    "        # infos['album'] = infos['album'].apply(ast.literal_eval)    #필요없는듯?\n",
    "\n",
    "        infos['track_artist'] = infos['artists'].apply(lambda x: ', '.join([artist['name'] for artist in x]))\n",
    "        infos['track_album_id'] = infos['album'].apply(lambda x: x['id'])\n",
    "        infos['track_album_name'] = infos['album'].apply(lambda x: x['name'])\n",
    "        infos['track_album_release_date'] = infos['album'].apply(lambda x: x['release_date'])\n",
    "\n",
    "        features.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "        infos.rename(columns={'id': 'track_id', 'name': 'track_name', 'popularity': 'track_popularity'}, inplace=True)\n",
    "\n",
    "        # 필요한거 골라서 합치기\n",
    "        df1_selected = features[['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                            'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                            'valence', 'tempo', 'duration_ms']]\n",
    "\n",
    "        df2_selected = infos[['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
    "                            'track_album_id', 'track_album_name', 'track_album_release_date']]\n",
    "\n",
    "        df_combined = pd.merge(df1_selected, df2_selected, on='track_id', how='inner')\n",
    "\n",
    "        # 순서 맞추기\n",
    "        df_combined = df_combined[df.columns]\n",
    "\n",
    "        # 원본 뒤에 붙이고 저장하기\n",
    "        df_merged = pd.concat([df, df_combined], ignore_index=True)\n",
    "        df_merged.drop_duplicates(subset='track_id', inplace=True)\n",
    "        df_merged.to_csv('../data/spotify_songs_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/spotify_songs.csv')\n",
    "# features = pd.read_csv('../data/audio_featrues.csv')\n",
    "# infos = pd.read_csv('../data/track_infos.csv')\n",
    "\n",
    "# # 필요한 컬럼 생성\n",
    "# infos['artists'] = infos['artists'].apply(ast.literal_eval)\n",
    "# infos['album'] = infos['album'].apply(ast.literal_eval)\n",
    "\n",
    "# infos['track_artist'] = infos['artists'].apply(lambda x: ', '.join([artist['name'] for artist in x]))\n",
    "# infos['track_album_id'] = infos['album'].apply(lambda x: x['id'])\n",
    "# infos['track_album_name'] = infos['album'].apply(lambda x: x['name'])\n",
    "# infos['track_album_release_date'] = infos['album'].apply(lambda x: x['release_date'])\n",
    "\n",
    "# features.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "# infos.rename(columns={'id': 'track_id', 'name': 'track_name', 'popularity': 'track_popularity'}, inplace=True)\n",
    "\n",
    "# # 필요한거 골라서 합치기\n",
    "# df1_selected = features[['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "#                     'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "#                     'valence', 'tempo', 'duration_ms']]\n",
    "\n",
    "# df2_selected = infos[['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
    "#                     'track_album_id', 'track_album_name', 'track_album_release_date']]\n",
    "\n",
    "# df_combined = pd.merge(df1_selected, df2_selected, on='track_id', how='inner')\n",
    "\n",
    "# # 원본데이터 수정\n",
    "# drop_col = ['playlist_id', 'playlist_name', 'playlist_genre', 'playlist_subgenre']\n",
    "# df.drop(columns=drop_col, inplace=True)\n",
    "\n",
    "# # 순서 맞추기\n",
    "# df_combined = df_combined[df.columns]\n",
    "\n",
    "# # 원본 뒤에 붙이고 저장하기\n",
    "# df_merged = pd.concat([df, df_combined], ignore_index=True)\n",
    "# df_merged.to_csv('../data/spotify_songs_new.csv')\n",
    "\n",
    "# # print(df.shape[0] + df_combined.shape[0])\n",
    "# # print(df_merged.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # API로 audio features 호출\n",
    "# def get_audio_features(sp, ids):\n",
    "#     audio_features = []\n",
    "#     id_chunks = list(chunk_ids(ids))\n",
    "#     total_chunks = len(id_chunks)\n",
    "\n",
    "#     for idx, chunk in enumerate(id_chunks):\n",
    "#         rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "#         try:\n",
    "#             features = sp.audio_features(chunk)\n",
    "#             if features is not None:\n",
    "#                 audio_features.extend(features)\n",
    "#             else:\n",
    "#                 print(f\"Chunk {idx+1}/{total_chunks}: Received None for features.\")\n",
    "#             print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error fetching audio features for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "#             # 필요에 따라 재시도 로직 추가 가능\n",
    "#     return audio_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio features 호출\n",
    "audio_features = get_audio_features(sp, ids)\n",
    "df = pd.DataFrame(audio_features)\n",
    "\n",
    "df.to_csv('../data/audio_featrues.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/new_songs.csv')\n",
    "\n",
    "# # 'id' 컬럼만 추출\n",
    "# ids = df['id'].tolist()\n",
    "\n",
    "# # 트랙은 50개씩 호출가능\n",
    "# def chunk_ids(ids, chunk_size=50):\n",
    "#     for i in range(0, len(ids), chunk_size):\n",
    "#         yield ids[i:i + chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # API로 audio features 호출\n",
    "# def get_track_info(sp, ids):\n",
    "#     track_info = []\n",
    "#     id_chunks = list(chunk_ids(ids))\n",
    "#     total_chunks = len(id_chunks)\n",
    "\n",
    "#     for idx, chunk in enumerate(id_chunks):\n",
    "#         rate_limiter.acquire()  # 호출 전에 RateLimiter를 통해 제한 관리\n",
    "#         try:\n",
    "#             response = sp.tracks(chunk)\n",
    "#             tracks = response['tracks']\n",
    "#             if tracks:\n",
    "#                 track_info.extend(tracks)\n",
    "#             else:\n",
    "#                 print(f\"Chunk {idx+1}/{total_chunks}: Received empty tracks.\")\n",
    "#             print(f\"Chunk {idx+1}/{total_chunks} processed.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error fetching track info for chunk {idx+1}/{total_chunks}: {e}\")\n",
    "#             # 필요에 따라 재시도 로직 추가 가능\n",
    "#     return track_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio features 호출\n",
    "track_infos = get_track_info(sp, ids)\n",
    "features = pd.DataFrame(track_infos)\n",
    "\n",
    "features.to_csv('../data/track_infos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/spotify_songs.csv')\n",
    "features = pd.read_csv('../data/audio_featrues.csv')\n",
    "infos = pd.read_csv('../data/track_infos.csv')\n",
    "\n",
    "# 필요한 컬럼 생성\n",
    "infos['artists'] = infos['artists'].apply(ast.literal_eval)\n",
    "infos['album'] = infos['album'].apply(ast.literal_eval)\n",
    "\n",
    "infos['track_artist'] = infos['artists'].apply(lambda x: ', '.join([artist['name'] for artist in x]))\n",
    "infos['track_album_id'] = infos['album'].apply(lambda x: x['id'])\n",
    "infos['track_album_name'] = infos['album'].apply(lambda x: x['name'])\n",
    "infos['track_album_release_date'] = infos['album'].apply(lambda x: x['release_date'])\n",
    "\n",
    "features.rename(columns={'id': 'track_id'}, inplace=True)\n",
    "infos.rename(columns={'id': 'track_id', 'name': 'track_name', 'popularity': 'track_popularity'}, inplace=True)\n",
    "\n",
    "# 필요한거 골라서 합치기\n",
    "df1_selected = features[['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
    "                    'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
    "                    'valence', 'tempo', 'duration_ms']]\n",
    "\n",
    "df2_selected = infos[['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
    "                    'track_album_id', 'track_album_name', 'track_album_release_date']]\n",
    "\n",
    "df_combined = pd.merge(df1_selected, df2_selected, on='track_id', how='inner')\n",
    "\n",
    "# 원본데이터 수정\n",
    "drop_col = ['playlist_id', 'playlist_name', 'playlist_genre', 'playlist_subgenre']\n",
    "df.drop(columns=drop_col, inplace=True)\n",
    "\n",
    "# 순서 맞추기\n",
    "df_combined = df_combined[df.columns]\n",
    "\n",
    "# 원본 뒤에 붙이고 저장하기\n",
    "df_merged = pd.concat([df, df_combined], ignore_index=True)\n",
    "df_merged.to_csv('../data/spotify_songs_new.csv')\n",
    "\n",
    "# print(df.shape[0] + df_combined.shape[0])\n",
    "# print(df_merged.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'danceability', 'energy', 'key', 'loudness', 'mode',\n",
       "       'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
       "       'valence', 'tempo', 'duration_ms', 'track_name', 'track_artist',\n",
       "       'track_popularity', 'track_album_id', 'track_album_name',\n",
       "       'track_album_release_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_id', 'track_name', 'track_artist', 'track_popularity',\n",
       "       'track_album_id', 'track_album_name', 'track_album_release_date',\n",
       "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'duration_ms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col = ['playlist_id', 'playlist_name', 'playlist_genre', 'playlist_subgenre']\n",
    "df.drop(columns=drop_col, inplace=True)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "# sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "\n",
    "# release_date = '2021-01-01'\n",
    "# query = f'release:{release_date}'\n",
    "# # song = 'dynamite'\n",
    "# track_info = sp.search(q=query, type='track')\n",
    "# track_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(track_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Spotify_audio_features:\n",
    "#     def __init__(self):\n",
    "\n",
    "#         client_credentials_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "#         self.sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "#     def get_features(self, song):\n",
    "#         # get track id information\n",
    "#         track_info = self.sp.search(q=song, type='track')\n",
    "#         track_id = track_info[\"tracks\"][\"items\"][0][\"id\"]\n",
    "\n",
    "#         # get audio_feature\n",
    "#         features = self.sp.audio_features(tracks=[track_id])\n",
    "#         acousticness = features[0][\"acousticness\"]\n",
    "#         danceability = features[0][\"danceability\"]\n",
    "#         energy = features[0][\"energy\"]\n",
    "#         liveness = features[0][\"liveness\"]\n",
    "#         loudness = features[0][\"loudness\"]\n",
    "#         valence = features[0][\"valence\"]\n",
    "#         mode = features[0][\"mode\"]\n",
    "\n",
    "#         result = {\"acousticness\" : acousticness,\n",
    "#                     \"danceability\" : danceability,\n",
    "#                     \"energy\" : energy,\n",
    "#                     \"liveness\" : liveness,\n",
    "#                     \"loudness\" : loudness,\n",
    "#                     \"valence\" : valence,\n",
    "#                     \"mode\" : mode}\n",
    "\n",
    "#         return result\n",
    "\n",
    "# spotify_audio = Spotify_audio_features()\n",
    "\n",
    "# # get_features 메서드 호출\n",
    "# song1 = spotify_audio.get_features('dynamite')\n",
    "\n",
    "# song1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "# sp = spotipy.Spotify(auth_manager=auth_manager)\n",
    "\n",
    "# # API 호출 시 Rate Limiting을 체크하고 처리하는 함수\n",
    "# def safe_api_call(api_call, *args, **kwargs):\n",
    "#     while True:\n",
    "#         try:\n",
    "#             # Spotify API 호출\n",
    "#             return api_call(*args, **kwargs)\n",
    "#         except SpotifyException as e:\n",
    "#             if e.http_status == 429:\n",
    "#                 # Retry-After 헤더 값 확인\n",
    "#                 retry_after = int(e.headers.get(\"Retry-After\", 10))\n",
    "#                 print(f\"Rate limit hit. Retrying after {retry_after} seconds.\")\n",
    "#                 time.sleep(retry_after)  # 지정된 시간만큼 대기 후 다시 시도\n",
    "#             else:\n",
    "#                 raise e  # 다른 예외 발생 시 에러 다시 발생\n",
    "#         except HTTPError as e:\n",
    "#             print(f\"HTTPError occurred: {e}\")\n",
    "#             raise e\n",
    "\n",
    "# # 특정 날짜에 발매된 트랙을 검색하여 필요한 정보를 DataFrame으로 정리하는 함수\n",
    "# def search_tracks_by_release_date(sp, release_date):\n",
    "#     tracks = []\n",
    "#     limit = 50\n",
    "#     offset = 0\n",
    "    \n",
    "#     while True:\n",
    "#         # 특정 날짜에 발매된 앨범을 쿼리\n",
    "#         query = f'release:{release_date}'\n",
    "#         results = safe_api_call(sp.search, q=query, type='album', limit=limit, offset=offset)\n",
    "#         albums = results['albums']['items']\n",
    "        \n",
    "#         if not albums:\n",
    "#             break  # 더 이상 결과가 없으면 중단\n",
    "\n",
    "#         # 각 앨범에서 트랙 정보를 가져오기\n",
    "#         for album in albums:\n",
    "#             album_id = album['id']\n",
    "#             album_name = album['name']\n",
    "#             album_release_date = album['release_date']\n",
    "\n",
    "#             # 앨범의 트랙 정보 가져오기\n",
    "#             album_tracks = safe_api_call(sp.album_tracks, album_id)['items']\n",
    "            \n",
    "#             for track in album_tracks:\n",
    "#                 track_id = track['id']\n",
    "#                 track_name = track['name']\n",
    "#                 track_artists = ', '.join([artist['name'] for artist in track['artists']])\n",
    "#                 track_popularity = safe_api_call(sp.track, track_id)['popularity']\n",
    "\n",
    "#                 # 트랙의 오디오 피처 (음악 분석 정보)\n",
    "#                 audio_features = safe_api_call(sp.audio_features, track_id)[0]\n",
    "                \n",
    "#                 if audio_features:\n",
    "#                     # 필요한 정보를 딕셔너리로 저장\n",
    "#                     track_info = {\n",
    "#                         'track_id': track_id,\n",
    "#                         'track_name': track_name,\n",
    "#                         'track_artist': track_artists,\n",
    "#                         'track_popularity': track_popularity,\n",
    "#                         'track_album_id': album_id,\n",
    "#                         'track_album_name': album_name,\n",
    "#                         'track_album_release_date': album_release_date,\n",
    "#                         'playlist_name': None,  # 필요하다면 추가적으로 연관된 Playlist API를 호출해 가져올 수 있음\n",
    "#                         'playlist_id': None,    # 필요하다면 연관된 Playlist 정보 추가\n",
    "#                         'playlist_genre': None, # 필요하다면 장르를 가져오도록 수정 가능\n",
    "#                         'playlist_subgenre': None,\n",
    "#                         'danceability': audio_features['danceability'],\n",
    "#                         'energy': audio_features['energy'],\n",
    "#                         'key': audio_features['key'],\n",
    "#                         'loudness': audio_features['loudness'],\n",
    "#                         'mode': audio_features['mode'],\n",
    "#                         'speechiness': audio_features['speechiness'],\n",
    "#                         'acousticness': audio_features['acousticness'],\n",
    "#                         'instrumentalness': audio_features['instrumentalness'],\n",
    "#                         'liveness': audio_features['liveness'],\n",
    "#                         'valence': audio_features['valence'],\n",
    "#                         'tempo': audio_features['tempo'],\n",
    "#                         'duration_ms': audio_features['duration_ms']\n",
    "#                     }\n",
    "#                     tracks.append(track_info)\n",
    "        \n",
    "#         offset += limit  # 다음 배치를 가져오기 위해 offset 증가\n",
    "\n",
    "#     # DataFrame으로 변환\n",
    "#     return pd.DataFrame(tracks)\n",
    "\n",
    "# # 발매일 설정 (예: 2020년 2월 2일)\n",
    "# release_date = '2020-02-02'\n",
    "# df_tracks = search_tracks_by_release_date(sp, release_date)\n",
    "\n",
    "# # DataFrame 출력\n",
    "# print(df_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_access_token(client_id, client_secret):\n",
    "#     \"\"\"스포티파이에서 액세스 토큰을 가져옵니다.\"\"\"\n",
    "#     url = 'https://accounts.spotify.com/api/token'\n",
    "#     headers = {'Content-Type': 'application/x-www-form-urlencoded'}\n",
    "#     data = {'grant_type': 'client_credentials'}\n",
    "\n",
    "#     while True:\n",
    "#         try:\n",
    "#             response = requests.post(url, headers=headers, data=data, auth=(client_id, client_secret))\n",
    "#             if response.status_code == 429:\n",
    "#                 retry_after = int(response.headers.get('Retry-After', 10))\n",
    "#                 print(f\"액세스 토큰을 가져오는 중에 레이트 리미트에 도달했습니다. {retry_after}초 후에 다시 시도합니다...\")\n",
    "#                 time.sleep(retry_after)\n",
    "#                 continue\n",
    "#             response.raise_for_status()\n",
    "#             break\n",
    "#         except requests.exceptions.HTTPError as e:\n",
    "#             print(f\"액세스 토큰 요청 중 에러 발생: {e}\")\n",
    "#             if response.status_code == 429:\n",
    "#                 retry_after = int(response.headers.get('Retry-After', 10))\n",
    "#                 print(f\"레이트 리미트에 도달했습니다. {retry_after}초 후에 다시 시도합니다...\")\n",
    "#                 time.sleep(retry_after)\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 raise  # 다른 에러는 다시 발생시킵니다.\n",
    "\n",
    "#     return response.json()['access_token']\n",
    "\n",
    "# def search_tracks_by_date(access_token, target_date):\n",
    "#     \"\"\"특정 날짜에 발매된 트랙을 검색합니다.\"\"\"\n",
    "#     url = 'https://api.spotify.com/v1/search'\n",
    "#     headers = {'Authorization': f'Bearer {access_token}'}\n",
    "#     query = 'year:2020-02'  # 2020년에 발매된 트랙 검색\n",
    "#     tracks_on_date = []\n",
    "#     limit = 50  # 한 번에 가져올 수 있는 최대 아이템 수\n",
    "#     offset = 0  # 검색 결과의 시작 지점\n",
    "\n",
    "#     while offset < 1000:  # 최대 1000개의 결과까지 가져올 수 있습니다\n",
    "#         params = {\n",
    "#             'q': query,\n",
    "#             'type': 'track',\n",
    "#             'limit': limit,\n",
    "#             'offset': offset\n",
    "#         }\n",
    "\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 response = requests.get(url, headers=headers, params=params)\n",
    "#                 if response.status_code == 429:\n",
    "#                     retry_after = int(response.headers.get('Retry-After', 10))\n",
    "#                     print(f\"레이트 리미트에 도달했습니다. {retry_after}초 후에 다시 시도합니다...\")\n",
    "#                     time.sleep(retry_after)\n",
    "#                     continue\n",
    "#                 response.raise_for_status()\n",
    "#                 break\n",
    "#             except requests.exceptions.HTTPError as e:\n",
    "#                 print(f\"트랙 검색 중 에러 발생: {e}\")\n",
    "#                 if response.status_code == 429:\n",
    "#                     retry_after = int(response.headers.get('Retry-After', 10))\n",
    "#                     print(f\"레이트 리미트에 도달했습니다. {retry_after}초 후에 다시 시도합니다...\")\n",
    "#                     time.sleep(retry_after)\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     raise  # 다른 에러는 다시 발생시킵니다.\n",
    "\n",
    "#         data = response.json()\n",
    "#         tracks = data.get('tracks', {}).get('items', [])\n",
    "\n",
    "#         if not tracks:\n",
    "#             break  # 더 이상의 결과가 없으면 종료\n",
    "\n",
    "#         for track in tracks:\n",
    "#             release_date = track['album']['release_date']\n",
    "#             release_precision = track['album']['release_date_precision']\n",
    "#             if release_precision == 'day' and release_date == target_date:\n",
    "#                 track_info = {\n",
    "#                     'name': track['name'],\n",
    "#                     'artists': ', '.join(artist['name'] for artist in track['artists']),\n",
    "#                     'release_date': release_date\n",
    "#                 }\n",
    "#                 tracks_on_date.append(track_info)\n",
    "\n",
    "#         offset += limit  # 다음 페이지로 이동\n",
    "\n",
    "#     return tracks_on_date\n",
    "\n",
    "# def main():\n",
    "#     access_token = get_access_token(client_id, client_secret)\n",
    "#     target_date = '2020-02-04'  # 검색할 발매일\n",
    "\n",
    "#     # 결과를 특정 변수에 저장합니다.\n",
    "#     search_results = search_tracks_by_date(access_token, target_date)\n",
    "\n",
    "#     # 필요에 따라 결과를 활용합니다.\n",
    "#     # 예를 들어, 결과를 출력하려면 아래 코드를 사용하세요.\n",
    "#     for idx, track in enumerate(search_results, 1):\n",
    "#         print(f\"{idx}. {track['name']} by {track['artists']} (Released on {track['release_date']})\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "\n",
    "# pprint.pprint(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
