{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a id=\"1\"></a>\n","# <div style=\"text-align:center; border-radius:15px 50px; padding:7px; color:white; margin:0; font-size:110%; font-family:Pacifico; background-color:#0073e6; overflow:hidden\"><b> Machine learning - Music Recommendation System KNN </b></div>\n","\n","![](https://img.freepik.com/vetores-gratis/site-de-feedbacks-de-dispositivos-eletronicos-avaliacao-do-cliente-de-compra_335657-2467.jpg?t=st=1725046930~exp=1725050530~hmac=2c4c04471ec02eae83eb6e7b9bd0fd79d2f07d83e48130e4e5f0b7fdff143a47&w=740)"]},{"cell_type":"markdown","metadata":{},"source":["# Part 1 Business problem - Music Recommendation System\n","\n","\n","#### Context\n","You have a dataset that contains detailed information about songs, including musical characteristics, popularity, and metadata related to albums and playlists. The goal is to create a recommendation system that can suggest relevant songs to users based on their musical interests, known and liked songs, or general preferences.\n","\n","#### Objective\n","Develop a recommendation system model that can suggest songs from an existing database using features such as `danceability`, `energy`, `valence`, among others. This system should be able to provide personalized recommendations for specific users or playlists, increasing user engagement and satisfaction.\n","\n","#### Justification\n","In the competitive digital music market, accurate and personalized recommendations are crucial for maintaining user engagement and promoting new songs. An effective recommendation system can not only increase playtime and user satisfaction but also help discover new talents and songs that align with the preferences of different audience segments.\n","\n","### Methodology\n","\n","1. **Exploratory Data Analysis (EDA):**\n","   - **Objective:** Understand the data distribution, detect outliers, and explore correlations between musical features and popularity.\n","   - **Tasks:**\n","     - Analyze the distribution of continuous variables (`danceability`, `energy`, `tempo`, etc.).\n","     - Explore the correlation between popularity (`track_popularity`) and musical characteristics.\n","\n","2. **Data Preprocessing:**\n","   - **Objective:** Prepare the data for the recommendation model.\n","   - **Tasks:**\n","     - Normalize continuous variables to ensure they are on the same scale.\n","     - Handle missing values or inconsistencies in the data.\n","\n","3. **Building the Recommendation Model:**\n","   - **Content-Based Filtering:**\n","     - **Objective:** Recommend songs similar to those based on their characteristics.\n","     - **Method:** Use KNN (K-Nearest Neighbors) with cosine similarity metric.\n","   - **Collaborative Filtering (if applicable):**\n","     - **Objective:** Recommend songs based on similar preferences of other users (if user interaction data is available).\n","   - **Hybrid Systems:**\n","     - **Objective:** Combine content-based and collaborative recommendations to improve accuracy.\n","\n","4. **Model Evaluation:**\n","   - **Objective:** Measure the effectiveness of the recommendations.\n","   - **Metrics:**\n","     - Recommendation accuracy (can be measured by RMSE if evaluation data is available).\n","     - Acceptance rate of recommendations (if interaction data is available).\n","   - **Tasks:**\n","     - Test different `k` values in KNN.\n","     - Validate the model with a test dataset.\n","\n","5. **Implementing the Recommendation System:**\n","   - **Objective:** Integrate the model into an application or service where it can provide real-time recommendations.\n","   - **Tasks:**\n","     - Create an API or web service that consumes the recommendation model.\n","     - Implement a feedback mechanism to improve recommendations over time.\n","\n","6. **Monitoring and Continuous Improvement:**\n","   - **Objective:** Maintain the effectiveness of the recommendation system over time.\n","   - **Tasks:**\n","     - Monitor the model's performance after deployment.\n","     - Periodically adjust and retrain the model with new data.\n","\n","### Expected Results\n","- **Relevant Recommendations:** The system should provide song recommendations that align with user preferences or the characteristics of specific songs.\n","- **Increased Engagement:** The system is expected to increase playtime and user satisfaction.\n","- **Discovery of New Music:** The system should help users . If you need more details or adjustments, I'm here to help!"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:20:47.12012Z","iopub.status.busy":"2024-08-30T22:20:47.118763Z","iopub.status.idle":"2024-08-30T22:21:00.362068Z","shell.execute_reply":"2024-08-30T22:21:00.360221Z","shell.execute_reply.started":"2024-08-30T22:20:47.12005Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting watermark\n","  Downloading watermark-2.5.0-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: ipython>=6.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from watermark) (8.27.0)\n","Collecting importlib-metadata>=1.4 (from watermark)\n","  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: setuptools in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from watermark) (74.1.2)\n","Collecting zipp>=3.20 (from importlib-metadata>=1.4->watermark)\n","  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: decorator in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.1.7)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (3.0.48)\n","Requirement already satisfied: pygments>=2.4.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (2.18.0)\n","Requirement already satisfied: stack-data in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (0.6.3)\n","Requirement already satisfied: traitlets>=5.13.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (5.14.3)\n","Requirement already satisfied: exceptiongroup in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (1.2.2)\n","Requirement already satisfied: typing-extensions>=4.6 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (4.12.2)\n","Requirement already satisfied: pexpect>4.3 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from ipython>=6.0->watermark) (4.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n","Requirement already satisfied: ptyprocess>=0.5 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n","Requirement already satisfied: wcwidth in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.0->watermark) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.1.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (2.4.1)\n","Requirement already satisfied: pure-eval in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.0->watermark) (0.2.3)\n","Requirement already satisfied: six>=1.12.0 in /Users/kwonsejin/Desktop/MLops/.venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.0->watermark) (1.16.0)\n","Downloading watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\n","Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n","Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n","Installing collected packages: zipp, importlib-metadata, watermark\n","Successfully installed importlib-metadata-8.5.0 watermark-2.5.0 zipp-3.20.2\n"]}],"source":["# Installing packages\n","!pip install watermark"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:04.499346Z","iopub.status.busy":"2024-08-30T22:21:04.498869Z","iopub.status.idle":"2024-08-30T22:21:04.951146Z","shell.execute_reply":"2024-08-30T22:21:04.949886Z","shell.execute_reply.started":"2024-08-30T22:21:04.49929Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:06.55785Z","iopub.status.busy":"2024-08-30T22:21:06.55723Z","iopub.status.idle":"2024-08-30T22:21:07.607261Z","shell.execute_reply":"2024-08-30T22:21:07.60588Z","shell.execute_reply.started":"2024-08-30T22:21:06.557806Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Matplotlib is building the font cache; this may take a moment.\n"]},{"name":"stdout","output_type":"stream","text":["Python version in this Jupyter Notebook: 3.10.15\n","Author: Library versions\n","\n","plotly    : 5.24.1\n","numpy     : 2.1.1\n","sklearn   : 1.5.2\n","platform  : 1.0.8\n","pandas    : 2.2.3\n","watermark : 2.5.0\n","seaborn   : 0.13.2\n","matplotlib: 3.9.2\n","re        : 2.2.1\n","\n"]}],"source":["# Import of libraries\n","\n","# System libraries\n","import re\n","import unicodedata\n","import itertools\n","\n","# Library for file manipulation\n","import pandas as pd\n","import numpy as np\n","import pandas\n","\n","# Data visualization\n","import seaborn as sns\n","import matplotlib.pylab as pl\n","import matplotlib as m\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","from matplotlib import pyplot as plt\n","\n","# Machine learning\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# Configuration for graph width and layout\n","sns.set_theme(style='whitegrid')\n","palette='viridis'\n","\n","# Warnings remove alerts\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Python version\n","from platform import python_version\n","print('Python version in this Jupyter Notebook:', python_version())\n","\n","# Load library versions\n","import watermark\n","\n","# Library versions\n","%reload_ext watermark\n","%watermark -a \"Library versions\" --iversions"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2 - Database"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:07.610152Z","iopub.status.busy":"2024-08-30T22:21:07.60933Z","iopub.status.idle":"2024-08-30T22:21:07.945591Z","shell.execute_reply":"2024-08-30T22:21:07.944065Z","shell.execute_reply.started":"2024-08-30T22:21:07.610098Z"},"trusted":true},"outputs":[],"source":["# Database\n","df = pd.read_csv(\"/kaggle/input/30000-spotify-songs/spotify_songs.csv\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:08.433073Z","iopub.status.busy":"2024-08-30T22:21:08.432608Z","iopub.status.idle":"2024-08-30T22:21:08.465774Z","shell.execute_reply":"2024-08-30T22:21:08.464276Z","shell.execute_reply.started":"2024-08-30T22:21:08.43303Z"},"trusted":true},"outputs":[],"source":["# Viewing first 5 data\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:09.185822Z","iopub.status.busy":"2024-08-30T22:21:09.18535Z","iopub.status.idle":"2024-08-30T22:21:09.212413Z","shell.execute_reply":"2024-08-30T22:21:09.211178Z","shell.execute_reply.started":"2024-08-30T22:21:09.185771Z"},"trusted":true},"outputs":[],"source":["# Viewing 5 latest data\n","df.tail()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:09.484539Z","iopub.status.busy":"2024-08-30T22:21:09.484068Z","iopub.status.idle":"2024-08-30T22:21:09.518108Z","shell.execute_reply":"2024-08-30T22:21:09.516165Z","shell.execute_reply.started":"2024-08-30T22:21:09.484496Z"},"trusted":true},"outputs":[],"source":["# Info data\n","df.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:09.803938Z","iopub.status.busy":"2024-08-30T22:21:09.803371Z","iopub.status.idle":"2024-08-30T22:21:09.815162Z","shell.execute_reply":"2024-08-30T22:21:09.81275Z","shell.execute_reply.started":"2024-08-30T22:21:09.803884Z"},"trusted":true},"outputs":[],"source":["# Type data\n","df.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:10.055534Z","iopub.status.busy":"2024-08-30T22:21:10.055081Z","iopub.status.idle":"2024-08-30T22:21:10.063453Z","shell.execute_reply":"2024-08-30T22:21:10.062074Z","shell.execute_reply.started":"2024-08-30T22:21:10.055491Z"},"trusted":true},"outputs":[],"source":["# Viewing rows and columns\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:10.395561Z","iopub.status.busy":"2024-08-30T22:21:10.395047Z","iopub.status.idle":"2024-08-30T22:21:10.404784Z","shell.execute_reply":"2024-08-30T22:21:10.403501Z","shell.execute_reply.started":"2024-08-30T22:21:10.395511Z"},"trusted":true},"outputs":[],"source":["# Copy data\n","data = df.copy()"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2 - Exploratory data analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:11.560191Z","iopub.status.busy":"2024-08-30T22:21:11.559755Z","iopub.status.idle":"2024-08-30T22:21:11.94869Z","shell.execute_reply":"2024-08-30T22:21:11.947229Z","shell.execute_reply.started":"2024-08-30T22:21:11.56015Z"},"trusted":true},"outputs":[],"source":["# Average popularity by playlist genre, sorted in descending order\n","playlist_popularity = data.groupby('playlist_genre')['track_popularity'].mean().sort_values(ascending=False)\n","\n","# Plotting with improvements\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=playlist_popularity.values, y=playlist_popularity.index, palette='magma')\n","\n","# Adding data labels\n","for index, value in enumerate(playlist_popularity.values):\n","    plt.text(value, index, f'{value:.1f}', va='center', ha='left', color='black')\n","\n","# Enhancing readability\n","plt.title('Average Popularity by Playlist Genre', fontsize=16)\n","plt.xlabel('Average Popularity', fontsize=12)\n","plt.ylabel('Playlist Genre', fontsize=12)\n","plt.xticks(fontsize=10)\n","plt.yticks(fontsize=10)\n","\n","# Adding gridlines for comparison\n","plt.grid(axis='x', linestyle='--', alpha=0.7)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:12.891827Z","iopub.status.busy":"2024-08-30T22:21:12.891384Z","iopub.status.idle":"2024-08-30T22:21:13.304194Z","shell.execute_reply":"2024-08-30T22:21:13.302996Z","shell.execute_reply.started":"2024-08-30T22:21:12.891788Z"},"trusted":true},"outputs":[],"source":["# Assuming your DataFrame is named df and has a 'track_album_release_date' column\n","data['year'] = pd.to_datetime(data['track_album_release_date'], errors='coerce').dt.year\n","\n","# Counting the number of songs released each year\n","yearly_tracks = data['year'].value_counts().sort_index()\n","\n","# Now, proceed with the rest of your code:\n","# Removing the most recent year if it's incomplete\n","yearly_tracks = yearly_tracks[yearly_tracks.index < 2023]  # Adjust the year based on your dataset\n","\n","# Smoothing the trend with a rolling average\n","yearly_tracks_smoothed = yearly_tracks.rolling(window=3, center=True).mean()\n","\n","# Plotting the smoothed trend with annotations and color coding\n","plt.figure(figsize=(10, 6))\n","sns.lineplot(x=yearly_tracks_smoothed.index, y=yearly_tracks_smoothed.values, marker='o', color='blue')\n","plt.title('Song Distribution by Release Year')\n","plt.xlabel('Year')\n","plt.ylabel('Number of Songs')\n","plt.grid(True)\n","\n","# Adding annotations for key points\n","max_year = yearly_tracks.idxmax()\n","max_value = yearly_tracks.max()\n","plt.annotate(f'Maximum in {max_year}', xy=(max_year, max_value), xytext=(max_year-10, max_value + 500),\n","             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n","\n","# Color coding different eras\n","plt.fill_between(yearly_tracks_smoothed.index, yearly_tracks_smoothed.values, where=yearly_tracks_smoothed.index < 2000, color='skyblue', alpha=0.5)\n","plt.fill_between(yearly_tracks_smoothed.index, yearly_tracks_smoothed.values, where=yearly_tracks_smoothed.index >= 2000, color='orange', alpha=0.5)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:14.296664Z","iopub.status.busy":"2024-08-30T22:21:14.296178Z","iopub.status.idle":"2024-08-30T22:21:14.910334Z","shell.execute_reply":"2024-08-30T22:21:14.90864Z","shell.execute_reply.started":"2024-08-30T22:21:14.296617Z"},"trusted":true},"outputs":[],"source":["from statsmodels.nonparametric.smoothers_lowess import lowess\n","\n","# Assuming your DataFrame is named df and has 'track_popularity' and 'track_album_release_date' columns\n","#df['year'] = pd.to_datetime(df['track_album_release_date'], errors='coerce').dt.year\n","\n","# Calculate the average popularity for each year\n","yearly_popularity = data.groupby('year')['track_popularity'].mean()\n","\n","# Calculate smoothed trend line\n","smoothed = lowess(yearly_popularity.values, yearly_popularity.index, frac=0.1)\n","\n","plt.figure(figsize=(20.5, 10))\n","sns.lineplot(x=yearly_popularity.index, y=yearly_popularity.values, marker='o', color='blue')\n","plt.plot(smoothed[:, 0], smoothed[:, 1], color='red', lw=2, label='Smoothed Trend')\n","plt.title('Popularity Trend Over the Years', fontsize=16)\n","plt.xlabel('Year', fontsize=12)\n","plt.ylabel('Average Popularity', fontsize=12)\n","\n","# Annotate the peak and trough\n","max_year = yearly_popularity.idxmax()\n","max_value = yearly_popularity.max()\n","plt.annotate(f'Highest in {max_year}', xy=(max_year, max_value), xytext=(max_year-10, max_value+5),\n","             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n","\n","min_year = yearly_popularity.idxmin()\n","min_value = yearly_popularity.min()\n","plt.annotate(f'Lowest in {min_year}', xy=(min_year, min_value), xytext=(min_year-10, min_value-5),\n","             arrowprops=dict(facecolor='black', arrowstyle=\"->\"))\n","\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:15.135157Z","iopub.status.busy":"2024-08-30T22:21:15.134449Z","iopub.status.idle":"2024-08-30T22:21:16.109648Z","shell.execute_reply":"2024-08-30T22:21:16.108372Z","shell.execute_reply.started":"2024-08-30T22:21:15.135112Z"},"trusted":true},"outputs":[],"source":["# plot Danceability Distribution\n","plt.figure(figsize=(20.5, 10))\n","sns.kdeplot(df['danceability'], shade=True, label='Danceability', color='blue', alpha=0.5, bw_adjust=0.7)\n","sns.kdeplot(df['energy'], shade=True, label='Energy', color='red', alpha=0.5, bw_adjust=0.7)\n","plt.axvline(df['danceability'].mean(), color='blue', linestyle='--', label='Danceability Mean')\n","plt.axvline(df['energy'].mean(), color='red', linestyle='--', label='Energy Mean')\n","plt.title('Danceability Distribution', fontsize=16)\n","plt.xlabel('Value', fontsize=12)\n","plt.ylabel('Density', fontsize=12)\n","plt.legend(fontsize=12)\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:31.576842Z","iopub.status.busy":"2024-08-30T22:21:31.575591Z","iopub.status.idle":"2024-08-30T22:21:32.072362Z","shell.execute_reply":"2024-08-30T22:21:32.071124Z","shell.execute_reply.started":"2024-08-30T22:21:31.576707Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10, 6))\n","sns.lineplot(x='year', y='track_popularity', data=data, ci='sd', marker='o')\n","plt.axvspan(2000, 2010, color='gray', alpha=0.2, label='Digital Era')\n","plt.title('Average Popularity Trend Over the Years')\n","plt.xlabel('Year')\n","plt.ylabel('Average Popularity')\n","plt.legend()\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:33.510447Z","iopub.status.busy":"2024-08-30T22:21:33.509982Z","iopub.status.idle":"2024-08-30T22:21:36.440078Z","shell.execute_reply":"2024-08-30T22:21:36.43889Z","shell.execute_reply.started":"2024-08-30T22:21:33.510407Z"},"trusted":true},"outputs":[],"source":["numerical_columns = ['track_popularity', 'danceability', 'energy', 'loudness', 'speechiness', \n","                     'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n","\n","df[numerical_columns].hist(bins=15, figsize=(15, 10))\n","plt.suptitle('Distribution of Numerical Variables')\n","plt.show()\n","\n","# Frequency of categorical variables\n","print()\n","print(df['playlist_genre'].value_counts())\n","\n","# Top 10 most frequent artists\n","print()\n","print(df['track_artist'].value_counts().head(10)) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:36.442321Z","iopub.status.busy":"2024-08-30T22:21:36.441917Z","iopub.status.idle":"2024-08-30T22:21:46.055454Z","shell.execute_reply":"2024-08-30T22:21:46.054079Z","shell.execute_reply.started":"2024-08-30T22:21:36.44227Z"},"trusted":true},"outputs":[],"source":["# Creating the pairplot with scatter plots\n","g = sns.pairplot(df,\n","                 x_vars=['danceability', 'energy', 'valence', 'tempo'],\n","                 y_vars='track_popularity',\n","                 height=4,\n","                 aspect=1.5,  # Aspect ratio to make the plots wider\n","                 kind='scatter',  # Keep scatter plot to customize points\n","                 plot_kws={'s': 20, 'edgecolor': 'w', 'linewidth': 0.5}  # Customize the point size and edges\n",")\n","\n","# Manually adding regression lines\n","for ax in g.axes.flat:\n","    # Ensure we access the correct x and y data for the regression plot\n","    sns.regplot(\n","        x=ax.collections[0].get_offsets()[:, 0],  # Extracting x data from scatter plot\n","        y=ax.collections[0].get_offsets()[:, 1],  # Extracting y data from scatter plot\n","        ax=ax,\n","        scatter=False,  # Hide the scatter plot in the regplot to avoid duplication\n","        color='red',\n","        line_kws={'linewidth': 1.5}  # Customize the regression line width\n","    )\n","\n","# Adding titles for each subplot\n","for ax, feature in zip(g.axes.flat, ['Danceability', 'Energy', 'Valence', 'Tempo']):\n","    ax.set_title(f'Track Popularity vs {feature}')\n","\n","# Adding a general title for the entire figure\n","plt.suptitle('Relationship between Musical Features and Popularity', y=1.02)\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Part 3 - Training and testing division"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:54.524142Z","iopub.status.busy":"2024-08-30T22:21:54.523129Z","iopub.status.idle":"2024-08-30T22:21:54.553076Z","shell.execute_reply":"2024-08-30T22:21:54.551631Z","shell.execute_reply.started":"2024-08-30T22:21:54.524082Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split, GridSearchCV\n","\n","# Splitting the dataset into training and testing\n","train_data, test_data = train_test_split(df, test_size=0.25, random_state=42)\n","\n","print(\"Viewing training x_train\", train_data.shape)\n","print(\"Viewing test test_data\", test_data.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Part 4 - Matrix interaction"]},{"cell_type":"markdown","metadata":{},"source":["### What is an Interaction Matrix?\n","\n","An **interaction matrix** is a core concept in recommendation systems, particularly those based on **Collaborative Filtering**. It is a table (or matrix) that captures the relationships between two sets of entities, such as users and items (e.g., songs, movies, products), in a format that can be processed by recommendation algorithms.\n","\n","An **interaction matrix** is a matrix where:\n","\n","- **Rows** represent one set of entities, typically users.\n","- **Columns** represent another set of entities, typically items (such as songs, movies, or products).\n","- **Entries** in the matrix indicate the interaction between a user and an item.\n","\n","These interactions can be:\n","\n","- **Explicit:** Where users provide direct feedback, such as ratings for a movie (e.g., 1 to 5 stars).\n","- **Implicit:** Where the interaction is inferred from user behavior, such as the number of times a song was played, whether a product was purchased, or if an item was viewed.\n","\n","### Example\n","\n","Consider an example of an interaction matrix for a music recommendation system:\n","\n","| User \\ Track | Track 1 | Track 2 | Track 3 | Track 4 |\n","|--------------|---------|---------|---------|---------|\n","| User 1       | 5       | 0       | 3       | 0       |\n","| User 2       | 0       | 2       | 0       | 4       |\n","| User 3       | 1       | 0       | 5       | 3       |\n","\n","Here:\n","\n","- `User 1` rated `Track 1` with a 5, `Track 3` with a 3, and did not rate `Tracks 2` or `4`.\n","- `User 2` rated `Track 2` with a 2, and `Track 4` with a 4, and did not rate `Tracks 1` or `3`.\n","- `User 3` rated `Track 1` with a 1, `Track 3` with a 5, and `Track 4` with a 3, and did not rate `Track 2`.\n","\n","### Usage\n","\n","- **Recommendation:** The interaction matrix is used by recommendation algorithms to predict which items (songs, movies, etc.) a user might like based on the interactions of other users with similar items.\n","\n","- **Collaborative Filtering:** This type of recommendation system uses the interaction matrix to identify patterns and similarities between users (User-based Collaborative Filtering) or between items (Item-based Collaborative Filtering).\n","\n","### Construction of the Matrix\n","\n","To construct an interaction matrix in Python, you can use the `pivot` function from pandas, as shown below:\n","\n","### Conclusion\n","\n","An interaction matrix is a foundational component of many recommendation systems, as it summarizes the relationships between users and items in a structure that can be easily analyzed to generate personalized recommendations."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:56.984434Z","iopub.status.busy":"2024-08-30T22:21:56.983968Z","iopub.status.idle":"2024-08-30T22:21:57.254652Z","shell.execute_reply":"2024-08-30T22:21:57.253335Z","shell.execute_reply.started":"2024-08-30T22:21:56.984384Z"},"trusted":true},"outputs":[],"source":["# Converting to numpy matrix interaction_matrix_matrix = interaction_matrix.values\n","interaction_matrix = train_data.pivot_table(index='playlist_id', columns='track_id', values='track_popularity').fillna(0) "]},{"cell_type":"markdown","metadata":{},"source":["# Part 5 - Finding the value of K"]},{"cell_type":"markdown","metadata":{},"source":["### Definição para Encontrar o Valor de `k`\n","\n","**Finding the Value of `k`:** \n","\n","In machine learning, particularly in **K-Nearest Neighbors (KNN)** algorithms, the value of `k` determines the number of nearest neighbors that are taken into account when making a prediction or classification. Choosing the right value of `k` is essential because it significantly affects the model's performance.\n","\n","### Key Considerations:\n","\n","1. **Small `k`:** \n","   - A small value of `k`, such as `k=1`, makes the model sensitive to noise in the data. The model might have high variance, leading to overfitting, as it tries to perfectly match the training data.\n","\n","2. **Large `k`:** \n","   - A larger value of `k` provides a smoother decision boundary, which might reduce variance but increase bias. While this may improve generalization, it could also lead to underfitting, where the model is too simplistic.\n","\n","3. **Odd `k`:**\n","   - An odd value for `k` is often preferred in binary classification problems to avoid ties, especially when the number of classes is even.\n","\n","### Finding the Optimal `k`:\n","\n","1. **Cross-Validation:**\n","   - The most common method to find the optimal value of `k` is to use cross-validation. This involves running the algorithm with different values of `k` and selecting the one that provides the best performance on a validation dataset.\n","\n","2. **Elbow Method:**\n","   - Similar to how it’s used in clustering, the elbow method can also be applied by plotting the error rate against different values of `k`. The point where the error rate starts to flatten out is typically chosen as the optimal `k`.\n","\n","3. **Grid Search:**\n","   - A systematic way of searching for the optimal `k` by evaluating the model's performance across a range of `k` values.\n","\n","### Conclusion\n","\n","Finding the right value of `k` is a balance between ensuring the model is complex enough to capture patterns in the data (but not too complex that it overfits) and simple enough to generalize well to new data (but not too simple that it underfits)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:21:59.45517Z","iopub.status.busy":"2024-08-30T22:21:59.454709Z","iopub.status.idle":"2024-08-30T22:22:28.201726Z","shell.execute_reply":"2024-08-30T22:22:28.200412Z","shell.execute_reply.started":"2024-08-30T22:21:59.455131Z"},"trusted":true},"outputs":[],"source":["from sklearn.neighbors import NearestNeighbors\n","from sklearn.metrics import pairwise_distances\n","from sklearn.metrics import silhouette_score\n","\n","# List of k values to test\n","k_values = list(range(1, 31))\n","\n","# Metric to store the results\n","mean_distances = []\n","\n","# Loop to find the best k\n","for k in k_values:\n","    model = NearestNeighbors(n_neighbors=k, metric='cosine')\n","    model.fit(interaction_matrix)\n","    \n","    # Compute the distances and indices of the nearest neighbors\n","    distances, indices = model.kneighbors(interaction_matrix)\n","    \n","    # Calculate the average distance to the nearest neighbors\n","    mean_distance = np.mean(distances)\n","    mean_distances.append(mean_distance)\n","\n","# Plotting the average distance metric for different values of k\n","plt.figure(figsize=(10, 6))\n","plt.plot(k_values, mean_distances, marker='o')\n","plt.title('Average Distance for Different Values of k')\n","plt.xlabel('Number of Neighbors (k)')\n","plt.ylabel('Average Distance')\n","plt.grid(False)\n","plt.show()\n","\n","# Find the best k (the one that minimizes the average distance)\n","best_k = k_values[np.argmin(mean_distances)]\n","print(f\"Best value of k: {best_k}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Part 6 - Machine learning Collaborative Filtering-Based Recommendation Model"]},{"cell_type":"markdown","metadata":{},"source":["## Definition\n","\n","### Collaborative Filtering\n","\n","Collaborative Filtering is a popular technique for recommendation systems that relies on the behavior and preferences of multiple users to make personalized recommendations.\n","\n","### Steps to Implement Collaborative Filtering\n","\n","1. **Data Preparation:**\n","   - **User-Item Matrix Creation:** Construct a matrix where rows represent users and columns represent items (songs in this case). The value in each cell represents the interaction between a user and a song, such as a rating or the number of times the song was played.\n","   - **Handling Missing Values:** If a user has not interacted with a song, the corresponding cell can be treated as zero or left as missing.\n","\n","2. **Choose the Algorithm:**\n","   - **User-Based Collaborative Filtering:**\n","     - **Objective:** Recommend songs that similar users liked.\n","   - **Item-Based Collaborative Filtering:**\n","     - **Objective:** Recommend songs similar to the ones a user has already liked.\n","   - **Matrix Factorization:** Techniques like Singular Value Decomposition (SVD) can be used to reduce the dimensionality of the matrix and capture latent structures in user-item interactions.\n","\n","### Explanation:\n","- **KNN:** K-Nearest Neighbors is used here to find similar users or items based on the cosine similarity metric.\n","- **User-Based Filtering:** You can change the focus to item-based filtering by switching the perspective from users to items in the matrix.\n","- **Dimensionality Reduction:** Advanced techniques like SVD can further enhance the model by capturing latent factors in the data.\n","\n","### Next Steps:\n","- **Experiment with Different Metrics:** You can try different similarity metrics like `cosine`, `pearson`, etc., to see which works best.\n","- **Hyperparameter Tuning:** Adjust the `n_neighbors` parameter to find the optimal number of neighbors for your recommendations.\n","- **Cross-Validation:** Use cross-validation to ensure your model generalizes well to unseen data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:22:28.204174Z","iopub.status.busy":"2024-08-30T22:22:28.20378Z","iopub.status.idle":"2024-08-30T22:22:28.510903Z","shell.execute_reply":"2024-08-30T22:22:28.509659Z","shell.execute_reply.started":"2024-08-30T22:22:28.204136Z"},"trusted":true},"outputs":[],"source":["# Adjusting k to test a larger value \n","model = NearestNeighbors(n_neighbors=best_k, metric='cosine')\n","model.fit(interaction_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:22:28.512777Z","iopub.status.busy":"2024-08-30T22:22:28.512343Z","iopub.status.idle":"2024-08-30T22:22:30.084466Z","shell.execute_reply":"2024-08-30T22:22:30.08323Z","shell.execute_reply.started":"2024-08-30T22:22:28.512738Z"},"trusted":true},"outputs":[],"source":["# Plotting the Interaction Matrix\n","plt.figure(figsize=(10, 6))\n","plt.imshow(interaction_matrix, aspect='auto', cmap='viridis')\n","plt.title('Interaction Matrix - KNN model')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The heatmap you've generated, titled \"Matriz de Interação,\" visually represents the values within your interaction matrix. Each cell in the matrix corresponds to the interaction between a user (represented by the rows) and an item (represented by the columns). The color of each cell indicates the strength or magnitude of the interaction, with the color bar on the right showing the scale from lower values (darker colors) to higher values (brighter colors).\n","\n","### Key Observations:\n","1. **Color Distribution**: The matrix appears to have a varied distribution of interaction values, with a mix of lower and higher interactions spread across the matrix. The presence of different colors suggests that the interaction data is not homogeneous, which could be useful for making distinctions between different users or items.\n","\n","2. **Patterns**: The heatmap does not show obvious, large-scale patterns such as vertical or horizontal bands, which suggests that interactions might be spread relatively evenly among users and items. However, smaller clusters or patterns might be present.\n","\n","3. **Interpretation**: If this matrix represents, for example, user ratings of items or user-item interactions, the varied colors indicate differences in user preferences or engagement. Areas with brighter colors could represent items that are more popular or users that are more active, whereas darker areas might indicate lower interactions."]},{"cell_type":"markdown","metadata":{},"source":["# Part 7 - Making recommendation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:22:30.087592Z","iopub.status.busy":"2024-08-30T22:22:30.087181Z","iopub.status.idle":"2024-08-30T22:22:30.141438Z","shell.execute_reply":"2024-08-30T22:22:30.140159Z","shell.execute_reply.started":"2024-08-30T22:22:30.087553Z"},"trusted":true},"outputs":[],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:24:42.162525Z","iopub.status.busy":"2024-08-30T22:24:42.162054Z","iopub.status.idle":"2024-08-30T22:24:42.372477Z","shell.execute_reply":"2024-08-30T22:24:42.368846Z","shell.execute_reply.started":"2024-08-30T22:24:42.162482Z"},"trusted":true},"outputs":[],"source":["# Predefined song to base recommendations on\n","# Replace with the song you want to start with\n","default_song_name = \"Someone You Loved - Future Humans Remix\"  \n","\n","def recommend_songs(df, model, interaction_matrix, song_name=default_song_name, k=10):\n","    # Find the playlist(s) that contain the predefined song\n","    song_playlists = df[df['track_name'].str.contains(song_name, case=False, na=False)]['playlist_id'].unique()\n","    \n","    if len(song_playlists) == 0:\n","        print(\"Song not found in the dataset.\")\n","        return\n","    \n","    # Get the index of the first playlist where the song was found\n","    playlist_id = song_playlists[0]\n","    \n","    # Get unique playlist IDs and their corresponding indices in interaction_matrix\n","    unique_playlists = df['playlist_id'].unique()\n","    \n","    if playlist_id not in unique_playlists:\n","        print(\"Playlist ID not found in unique playlists.\")\n","        return\n","    \n","    playlist_index = np.where(unique_playlists == playlist_id)[0][0]\n","    \n","    # Find similar playlists using KNN\n","    try:\n","        # If interaction_matrix is a DataFrame, use .iloc to get the row\n","        if isinstance(interaction_matrix, pd.DataFrame):\n","            distances, indices = model.kneighbors(interaction_matrix.iloc[playlist_index].values.reshape(1, -1), n_neighbors=k+1)\n","        else:\n","            distances, indices = model.kneighbors(interaction_matrix[playlist_index].reshape(1, -1), n_neighbors=k+1)\n","    except IndexError:\n","        print(\"Playlist index is out of bounds in the interaction matrix.\")\n","        return\n","    \n","    # Remove the index of the original playlist\n","    similar_playlists = indices.flatten()[1:]  # Ignoring the first one, which is the original playlist\n","    \n","    # Identify songs to recommend\n","    original_playlist_tracks = set(df[df['playlist_id'] == playlist_id]['track_id'])\n","    recommended_tracks = set()\n","\n","    for idx in similar_playlists:\n","        similar_playlist_id = unique_playlists[idx]\n","        similar_playlist_tracks = set(df[df['playlist_id'] == similar_playlist_id]['track_id'])\n","        recommended_tracks.update(similar_playlist_tracks - original_playlist_tracks)\n","\n","    # Display the recommended songs\n","    if recommended_tracks:\n","        recommended_tracks_info = df[df['track_id'].isin(recommended_tracks)][['track_name', 'track_artist']].drop_duplicates()\n","        print(\"Recommended songs\")\n","        print(recommended_tracks_info)\n","    else:\n","        print(\"No new songs to recommend.\")\n","\n","# Example usage\n","# Assuming df, model, and interaction_matrix are already defined\n","print(\"Música selecionada\", default_song_name)\n","recommend_songs(df, model, interaction_matrix)"]},{"cell_type":"markdown","metadata":{},"source":["# Part 8 - Euclidean distance"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:24:48.698683Z","iopub.status.busy":"2024-08-30T22:24:48.697602Z","iopub.status.idle":"2024-08-30T22:24:49.321367Z","shell.execute_reply":"2024-08-30T22:24:49.320103Z","shell.execute_reply.started":"2024-08-30T22:24:48.698618Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics.pairwise import cosine_distances\n","\n","def plotar_distancias_musicas(interaction_matrix, df, playlist_index, k=10):\n","    # Calculate the cosine distance between the selected playlist and all others\n","    if isinstance(interaction_matrix, pd.DataFrame):\n","        cosine_distances_array = cosine_distances(interaction_matrix.iloc[playlist_index].values.reshape(1, -1), interaction_matrix)\n","    else:\n","        cosine_distances_array = cosine_distances(interaction_matrix[playlist_index].reshape(1, -1), interaction_matrix)\n","    \n","    # Sort the playlists based on the cosine distance\n","    sorted_indices = cosine_distances_array.argsort().flatten()\n","    \n","    # Ignore the first index as it will be the playlist itself\n","    similar_playlists = sorted_indices[1:k+1]\n","    \n","    # Extract the cosine distances of the recommended playlists\n","    similar_playlists_distances = cosine_distances_array.flatten()[similar_playlists]\n","    \n","    # Map the most popular songs from each similar playlist\n","    music_names = []\n","    for idx in similar_playlists:\n","        playlist_id = df['playlist_id'].unique()[idx]\n","        popular_music = df[df['playlist_id'] == playlist_id].sort_values(by='track_popularity', ascending=False).iloc[0]\n","        music_names.append(f\"{popular_music['track_name']} - {popular_music['track_artist']}\")\n","    \n","    # Plot the cosine distances\n","    plt.figure(figsize=(10, 6))\n","    plt.barh(music_names, similar_playlists_distances, color='green')\n","    plt.xlabel('Cosine Distance')\n","    plt.ylabel('Recommended Songs')\n","    plt.title('Cosine Distances of the Most Similar Songs')\n","    plt.gca().invert_yaxis()  # Invert y-axis so the most similar song is at the top\n","    plt.grid(False)\n","    plt.show()\n","\n","# Example usage\n","playlist_index = 0  # Replace with the index of the playlist you want to analyze\n","plotar_distancias_musicas(interaction_matrix, df, playlist_index, k=10)"]},{"cell_type":"markdown","metadata":{},"source":[" **Playlist Optimization**: The business team can use this graph to curate or enhance playlists by adding songs that are similar to those already in a popular playlist. This can help in maintaining a consistent user experience in terms of music style and genre.\n","\n","- **Personalized Recommendations**: By understanding which songs are similar to those a user already likes, the business can make more personalized recommendations, increasing user engagement and satisfaction.\n","\n","- **Content Strategy**: The data can be used to identify which types of songs tend to cluster together, helping the business team understand trends in music preferences. This information can guide decisions about what new music or playlists to promote.\n","\n","- **Reducing Churn**: Offering users songs that are very similar to those they already enjoy can help in keeping them engaged with the platform, reducing the likelihood that they will churn or lose interest.\n","\n","This graph provides a clear visual representation of song similarities, helping the business team make informed decisions about playlist management, user engagement strategies, and music recommendation approaches."]},{"cell_type":"markdown","metadata":{},"source":["# Part 9 - Recommendation system - Group songs into clusters based on their characteristics and recommend songs within these clusters"]},{"cell_type":"markdown","metadata":{},"source":["A **Recommendation System** is an algorithmic tool that suggests items to users based on various criteria. In the context of music, a recommendation system analyzes the characteristics of songs, such as genre, tempo, energy, and other audio features, and groups them into clusters. These clusters represent groups of songs that share similar attributes. Once the songs are clustered, the recommendation system can suggest songs to users based on the clusters they are likely to enjoy. For example, if a user enjoys songs in a particular cluster, the system will recommend other songs within that cluster, ensuring the recommendations align with the user's musical preferences.\n","\n","This approach allows for more personalized recommendations, as it considers the inherent similarities between songs, making it easier to suggest new music that fits a user's taste."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:24:56.721512Z","iopub.status.busy":"2024-08-30T22:24:56.720106Z","iopub.status.idle":"2024-08-30T22:24:57.020808Z","shell.execute_reply":"2024-08-30T22:24:57.019374Z","shell.execute_reply.started":"2024-08-30T22:24:56.721447Z"},"trusted":true},"outputs":[],"source":["# Database \n","data = pd.read_csv(\"/kaggle/input/30000-spotify-songs/spotify_songs.csv\") \n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:24:57.894685Z","iopub.status.busy":"2024-08-30T22:24:57.894199Z","iopub.status.idle":"2024-08-30T22:24:57.902541Z","shell.execute_reply":"2024-08-30T22:24:57.900978Z","shell.execute_reply.started":"2024-08-30T22:24:57.894639Z"},"trusted":true},"outputs":[],"source":["# 1. Select the relevant features for clustering\n","features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n","            'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n","\n","X = data[features]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:24:58.935793Z","iopub.status.busy":"2024-08-30T22:24:58.935375Z","iopub.status.idle":"2024-08-30T22:24:58.953803Z","shell.execute_reply":"2024-08-30T22:24:58.952458Z","shell.execute_reply.started":"2024-08-30T22:24:58.93575Z"},"trusted":true},"outputs":[],"source":["# Scaling data\n","from sklearn.preprocessing import StandardScaler\n","\n","# Scale the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Viewing\n","scaler"]},{"cell_type":"markdown","metadata":{},"source":["# Number of Clusters\n","\n","**Number of Clusters** refers to the number of distinct groups or segments identified within a dataset when performing cluster analysis. Clustering is a technique used in data analysis and machine learning to group similar data points together based on certain characteristics or features. \n","\n","### In More Detail:\n","\n","1. **Clusters**:\n","   - A cluster is a collection of data points that are more similar to each other than to data points in other clusters. The similarity is often determined using distance metrics like Euclidean distance, cosine similarity, etc.\n","   - Each cluster represents a group of data points that share certain traits, making them distinct from points in other clusters.\n","\n","2. **Number of Clusters**:\n","   - The \"Number of Clusters\" is the count of these distinct groups. For example, if you set the number of clusters to 3 in a clustering algorithm, the algorithm will partition the data into 3 distinct groups.\n","   - The selection of the number of clusters (often denoted as *k* in algorithms like k-means) is a critical decision. If the number of clusters is too low, distinct groups in the data may be merged together; if it's too high, you may split data into too many small, less meaningful groups.\n","\n","3. **Determining the Optimal Number of Clusters**:\n","   - Choosing the right number of clusters is essential for effective clustering. Some common methods to determine the optimal number of clusters include:\n","     - **Elbow Method**: Plotting the sum of squared distances within clusters against the number of clusters. The optimal number of clusters is often found where the plot forms an \"elbow.\"\n","     - **Silhouette Score**: Measures how similar a point is to its own cluster compared to other clusters. Higher silhouette scores indicate better clustering.\n","     - **Gap Statistic**: Compares the total within intra-cluster variation for different numbers of clusters with their expected values under null reference distribution of the data.\n","\n","### Example in Business Context:\n","\n","- In customer segmentation, you might want to cluster your customers into groups based on their purchasing behavior. The number of clusters might represent the different customer segments you want to target with different marketing strategies. For example, if the algorithm identifies 3 clusters, they could represent high-value customers, medium-value customers, and low-value customers.\n","\n","Understanding and selecting the right number of clusters is key to effective segmentation and analysis, enabling more precise targeting and decision-making.decisão mais precisas."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:25:01.246888Z","iopub.status.busy":"2024-08-30T22:25:01.246406Z","iopub.status.idle":"2024-08-30T22:25:19.011966Z","shell.execute_reply":"2024-08-30T22:25:19.010689Z","shell.execute_reply.started":"2024-08-30T22:25:01.246845Z"},"trusted":true},"outputs":[],"source":["from sklearn.cluster import KMeans\n","\n","# Determine the optimal number of clusters using the elbow method\n","sse = []\n","k_range = range(1, 11)\n","for k in k_range:\n","    kmeans = KMeans(n_clusters=k, random_state=42)\n","    kmeans.fit(X_scaled)\n","    sse.append(kmeans.inertia_)\n","\n","# Plot the elbow plot\n","plt.figure(figsize=(8, 6))\n","plt.plot(k_range, sse, marker='o')\n","plt.xlabel('Number of Clusters')\n","plt.ylabel('Sum of Squared Distances (Inertia)')\n","plt.title('Elbow Method for Determining the Number of Clusters')\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:25:33.876517Z","iopub.status.busy":"2024-08-30T22:25:33.875983Z","iopub.status.idle":"2024-08-30T22:25:35.377399Z","shell.execute_reply":"2024-08-30T22:25:35.37596Z","shell.execute_reply.started":"2024-08-30T22:25:33.876474Z"},"trusted":true},"outputs":[],"source":["# 4. Apply K-Means with the chosen number of clusters\n","# Assume the optimal number of clusters is 5 (adjust as per the elbow plot)\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","data['cluster_kmeans'] = kmeans.fit_predict(X_scaled)\n","kmeans"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:25:35.380218Z","iopub.status.busy":"2024-08-30T22:25:35.379706Z","iopub.status.idle":"2024-08-30T22:25:35.390735Z","shell.execute_reply":"2024-08-30T22:25:35.389376Z","shell.execute_reply.started":"2024-08-30T22:25:35.380163Z"},"trusted":true},"outputs":[],"source":["# Viewing total cluster\n","data.cluster_kmeans.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:25:38.52701Z","iopub.status.busy":"2024-08-30T22:25:38.526545Z","iopub.status.idle":"2024-08-30T22:25:38.852096Z","shell.execute_reply":"2024-08-30T22:25:38.850901Z","shell.execute_reply.started":"2024-08-30T22:25:38.526966Z"},"trusted":true},"outputs":[],"source":["# Count of songs in each cluster\n","cluster_counts = data['cluster_kmeans'].value_counts().sort_values(ascending=False)\n","\n","# Calculate the percentage of each cluster\n","total_songs = cluster_counts.sum()\n","cluster_percentages = (cluster_counts / total_songs) * 100\n","\n","# Plot the distribution of clusters with percentages\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x=cluster_counts.index, y=cluster_counts.values, palette='deep')\n","plt.xlabel('Cluster')\n","plt.ylabel('Number of Songs')\n","plt.title('Distribution of Songs by Cluster')\n","\n","# Adding data labels on top of bars\n","for index, value in enumerate(cluster_counts):\n","    plt.text(index, value + 100, f'{value} ({cluster_percentages[index]:.1f}%)', ha='center', fontsize=12)\n","\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Part 9.1 - PCA \n","\n","Applying Principal Component Analysis (PCA) in a recommendation system can be beneficial for several reasons, particularly when dealing with high-dimensional data. Here’s why PCA might be applied in the context of a recommendation system:\n","\n","### 1. **Dimensionality Reduction**:\n","   - **High-Dimensional Data**: In music recommendation systems, you might have a large number of features for each song, such as tempo, energy, valence, loudness, danceability, and more. These features create a high-dimensional space.\n","   - **Reducing Complexity**: PCA helps reduce the number of dimensions while retaining most of the variance (information) in the data. This simplifies the dataset, making the recommendation system more computationally efficient and faster.\n","\n","### 2. **Noise Reduction**:\n","   - **Removing Redundant Information**: High-dimensional data often contains noise or redundant features that don’t contribute much to the decision-making process. PCA can help eliminate these less informative features, which might improve the accuracy of the recommendation system.\n","   - **Enhancing Signal**: By focusing on the principal components (the most significant features), the recommendation system can better capture the underlying patterns in the data, leading to more relevant recommendations.\n","\n","### 3. **Improved Model Performance**:\n","   - **Avoiding Overfitting**: In a high-dimensional space, models can become too complex and overfit the training data. PCA helps reduce the risk of overfitting by reducing the number of features, which can lead to a more generalizable model.\n","   - **Efficiency in Algorithms**: Algorithms like k-means clustering or k-nearest neighbors (KNN) used in recommendation systems can perform better and faster in a reduced-dimensional space. This makes PCA particularly useful in the preprocessing stage before applying such algorithms.\n","\n","### 4. **Visualization**:\n","   - **Understanding Data Clusters**: PCA can reduce dimensions to a level where the data can be visualized (e.g., in 2D or 3D). This visualization helps understand the clusters of songs, their relationships, and the distribution of user preferences, which can inform and refine the recommendation strategies.\n","\n","### 5. **Dealing with Sparsity**:\n","   - **Sparse Interaction Matrices**: In collaborative filtering, the user-item interaction matrix is often sparse (many zeros). PCA can help by compressing the matrix into a lower-dimensional space where the patterns (e.g., user preferences) become more apparent.\n","\n","### Summary:\n","Applying PCA in a recommendation system is a strategic way to reduce dimensionality, enhance the signal-to-noise ratio, and improve computational efficiency. By transforming the data into a lower-dimensional space, PCA allows the recommendation system to work more effectively, making it faster and potentially more accurate in providing personalized suggestions."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:28:55.907139Z","iopub.status.busy":"2024-08-30T22:28:55.906668Z","iopub.status.idle":"2024-08-30T22:28:55.975713Z","shell.execute_reply":"2024-08-30T22:28:55.974629Z","shell.execute_reply.started":"2024-08-30T22:28:55.907099Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","\n","# 2. Perform PCA Analysis\n","# Initialize the PCA model specifying the number of components to reduce to (in this case, 2 components).\n","pca = PCA(n_components=2)\n","\n","# Apply PCA on the scaled feature set X_scaled and transform the data into the new 2-dimensional space.\n","X_pca = pca.fit_transform(X_scaled)\n","\n","# Output the PCA model object, which contains information such as the amount of variance explained by each principal component.\n","pca"]},{"cell_type":"markdown","metadata":{},"source":["# Part 10 - Cluster visualization "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:29:05.104359Z","iopub.status.busy":"2024-08-30T22:29:05.103887Z","iopub.status.idle":"2024-08-30T22:29:08.996639Z","shell.execute_reply":"2024-08-30T22:29:08.995406Z","shell.execute_reply.started":"2024-08-30T22:29:05.104302Z"},"trusted":true},"outputs":[],"source":["# Apply K-Means clustering\n","kmeans = KMeans(n_clusters=4, random_state=42)\n","clusters = kmeans.fit_predict(X_scaled)\n","data['cluster_kmeans'] = clusters\n","\n","# Plotting the clusters\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x=X_pca[:, 0], \n","                y=X_pca[:, 1], \n","                hue=data['cluster_kmeans'], \n","                palette='viridis', \n","                alpha=0.6, \n","                edgecolor='k')\n","\n","# Adding the cluster centers\n","centers = kmeans.cluster_centers_\n","# Projecting the centers to the 2D PCA space\n","centers_pca = pca.transform(centers)\n","plt.scatter(centers_pca[:, 0], centers_pca[:, 1], \n","            c='red', \n","            s=200, \n","            marker='X', \n","            label='Cluster Centers')\n","\n","plt.title('Clusters after Applying K-Means')\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.legend()\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:29:09.998569Z","iopub.status.busy":"2024-08-30T22:29:09.998122Z","iopub.status.idle":"2024-08-30T22:29:12.468916Z","shell.execute_reply":"2024-08-30T22:29:12.467571Z","shell.execute_reply.started":"2024-08-30T22:29:09.998529Z"},"trusted":true},"outputs":[],"source":["# Plot\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=data['cluster_kmeans'], palette='viridis', s=70, alpha=0.7)\n","\n","# Plot the cluster centers\n","plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X', label='Centroides')\n","\n","plt.title('Visualization of Clusters after PCA')\n","plt.xlabel('Principal Component 1')\n","plt.ylabel('Principal Component 2')\n","plt.legend(title='Clusters')\n","plt.grid(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:29:12.471251Z","iopub.status.busy":"2024-08-30T22:29:12.470847Z","iopub.status.idle":"2024-08-30T22:29:12.508924Z","shell.execute_reply":"2024-08-30T22:29:12.507791Z","shell.execute_reply.started":"2024-08-30T22:29:12.471211Z"},"trusted":true},"outputs":[],"source":["# Assuming you want to calculate the mean of features for cluster 2 (since `== 2` is used)\n","cluster_1_features = data[data['cluster_kmeans'] == 0][features].mean()\n","print(\"Mean of Features for Cluster 0:\")\n","print(cluster_1_features)\n","print()\n","\n","# Assuming you want to calculate the mean of features for cluster 2 (since `== 2` is used)\n","cluster_2_features = data[data['cluster_kmeans'] == 1][features].mean()\n","print(\"Mean of Features for Cluster 1:\")\n","print(cluster_2_features)\n","print()\n","\n","# Assuming you want to calculate the mean of features for cluster 2 (since `== 2` is used)\n","cluster_3_features = data[data['cluster_kmeans'] == 2][features].mean()\n","print(\"Mean of Features for Cluster 2:\")\n","print(cluster_3_features)\n","print()\n","\n","# Assuming you want to calculate the mean of features for cluster 2 (since `== 2` is used)\n","cluster_4_features = data[data['cluster_kmeans'] == 3][features].mean()\n","print(\"Mean of Features for Cluster 3:\")\n","print(cluster_4_features)\n","print()"]},{"cell_type":"markdown","metadata":{},"source":["# Part 11 - Making Recommendation - Cluster Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:29:26.157453Z","iopub.status.busy":"2024-08-30T22:29:26.156964Z","iopub.status.idle":"2024-08-30T22:29:26.165876Z","shell.execute_reply":"2024-08-30T22:29:26.164619Z","shell.execute_reply.started":"2024-08-30T22:29:26.157404Z"},"trusted":true},"outputs":[],"source":["def recommend_songs_by_cluster_kmeans(song_name, data):\n","    # Search for the selected song in the dataset, ignoring case and handling missing values\n","    selected_song = data[data['track_name'].str.contains(song_name, case=False, na=False)]\n","    \n","    # If the song is not found, display a message and exit the function\n","    if selected_song.empty:\n","        print(\"Song not found.\")\n","        return None\n","    \n","    # Retrieve the cluster to which the selected song belongs\n","    cluster = selected_song['cluster_kmeans'].values[0]\n","    \n","    # Find all songs that belong to the same cluster as the selected song\n","    recommended_songs = data[data['cluster_kmeans'] == cluster]\n","    \n","    # Exclude the selected song from the recommendations\n","    recommended_songs = recommended_songs[recommended_songs['track_name'] != selected_song['track_name'].values[0]]\n","    \n","    # Return only the 'track_name' and 'track_artist' columns, limited to the top 25 recommendations\n","    return recommended_songs[['track_name', 'track_artist']].head(30)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-30T22:29:48.147955Z","iopub.status.busy":"2024-08-30T22:29:48.147113Z","iopub.status.idle":"2024-08-30T22:29:48.193797Z","shell.execute_reply":"2024-08-30T22:29:48.192416Z","shell.execute_reply.started":"2024-08-30T22:29:48.147906Z"},"trusted":true},"outputs":[],"source":["# Example of usage\n","# Replace with the name of the song you want to use as the base for recommendations\n","song_name = \"Shape of You\"  \n","top_recommendations_kmeans = recommend_songs_by_cluster_kmeans(song_name, data)\n","\n","# If recommendations are found, print them\n","if top_recommendations_kmeans is not None:\n","    print(\"Recommended music\")\n","    print(top_recommendations_kmeans)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":3938173,"sourceId":6851382,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":4}
